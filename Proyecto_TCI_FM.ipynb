{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16749f1c-52ee-4c11-976b-982662139a39",
   "metadata": {},
   "source": [
    "# Proyecto Tópicos Intensivos de Computación Estadística\n",
    "\n",
    "Fernando Moreno\n",
    "\n",
    "Noviembre de 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b25f8-2911-4f2d-bc95-1798cfa9b94d",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc4b6b-bf5d-4b4c-aa98-e7df48384ea9",
   "metadata": {},
   "source": [
    "[40 Open-Source Audio Datasets for ML](https://towardsdatascience.com/40-open-source-audio-datasets-for-ml-59dc39d48f06)\n",
    "\n",
    "\n",
    "+ [Audio MNIST](https://www.kaggle.com/datasets/sripaadsrinivasan/audio-mnist)\n",
    "\n",
    "[Github repo](https://github.com/soerenab/AudioMNIST)\n",
    "\n",
    "Context:\n",
    "A Large dataset of Audio MNIST, 30000 audio samples of spoken digits (0-9) of 60 different speakers.\n",
    "\n",
    "Content\n",
    "data (audioMNIST)\n",
    "\n",
    "The dataset consists of 30000 audio samples of spoken digits (0-9) of 60 folders and 500 files each.\n",
    "There is one directory per speaker holding the audio recordings.\n",
    "Additionally \"audioMNIST_meta.txt\" provides meta information such as gender or age of each speaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdf58b-c54b-4c33-9d35-85172407ad8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf309d6-486c-441d-b59e-33368e891669",
   "metadata": {},
   "source": [
    "+ [Keras Code examples](https://keras.io/examples/)\n",
    "\n",
    "    **Audio Data**: \n",
    "\n",
    "     Automatic Speech Recognition using CTC\n",
    "    \n",
    "     MelGAN-based spectrogram inversion using feature matching\n",
    "    \n",
    "     [Speaker Recognition](https://keras.io/examples/audio/speaker_recognition_using_cnn/)\n",
    "     \n",
    "            Author: Fadi Badine\n",
    "    \n",
    "            Date created: 14/06/2020\n",
    "    \n",
    "            Last modified: 03/07/2020\n",
    "    \n",
    "     Automatic Speech Recognition with Transformer\n",
    "    \n",
    "     English speaker accent recognition using Transfer Learning\n",
    "    \n",
    "     [Wav2Vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://towardsdatascience.com/wav2vec-2-0-a-framework-for-self-supervised-learning-of-speech-representations-7d3728688cae/)\n",
    "            \n",
    "     [Audio Classification with Hugging Face Transformers](https://keras.io/examples/audio/wav2vec2_audiocls/)\n",
    "            \n",
    "            Author: Sreyan Ghosh\n",
    "\n",
    "            Date created: 2022/07/01\n",
    "\n",
    "            Last modified: 2022/08/27\n",
    "\n",
    "            Description: Training Wav2Vec 2.0 using Hugging Face Transformers for Audio Classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
